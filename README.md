# ğŸŒ€ KNN U-Shape Classification Project

## ğŸ“˜ Overview
This project demonstrates the implementation of the **K-Nearest Neighbors (KNN)** algorithm using a **U-Shape dataset**. The main objective is to classify data points into two classes and visualize the **decision boundary** of the trained model.

## ğŸ“‚ Dataset
The dataset used is **ushape.csv** which contains two features (X, Y) and one target variable (class). It forms a U-shaped distribution, ideal for demonstrating how KNN handles non-linear patterns.

### Example of the dataset:
| X | Y | class |
|---|---|--------|
| 0.03 | 0.98 | 0 |
| 0.25 | 0.85 | 1 |
| 0.12 | 0.64 | 0 |

## âš™ï¸ Project Workflow
1ï¸âƒ£ **Import Libraries**  
Libraries like pandas, numpy, matplotlib, sklearn, and mlxtend were used for data manipulation, model building, and visualization.

2ï¸âƒ£ **Load and Rename Columns**  
The dataset was loaded using pandas and columns were renamed for clarity:  
`X`, `Y`, and `class`.

3ï¸âƒ£ **Data Visualization**  
The dataset was plotted using scatter plot with color mapping by class to show the U-shape data distribution.

4ï¸âƒ£ **Data Splitting and Scaling**  
The dataset was split into 70% training and 30% testing using train_test_split. StandardScaler was used for normalization to ensure uniform feature scaling.

5ï¸âƒ£ **Model Training using KNN**  
Multiple K values (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50) were tested using 10-fold cross-validation to determine the best K value. The best K was chosen based on the highest cross-validation accuracy score.

6ï¸âƒ£ **Best K Value Selection**  
The optimal K value was identified and used to train the final KNN model.

7ï¸âƒ£ **Decision Boundary Visualization**  
Using mlxtendâ€™s plot_decision_regions, the decision boundary for the best K value was plotted, showing clear classification regions of the two classes.

8ï¸âƒ£ **Model Evaluation**  
The trained model was evaluated on the test set using multiple metrics including Accuracy, Precision, Recall, F1 Score, and AUC-ROC.

## ğŸ“Š Results Summary
| Metric | Description | Result |
|---------|--------------|--------|
| **Accuracy** | Overall model correctness | High |
| **Precision** | Correct positive predictions | Good |
| **Recall** | True positive rate | Balanced |
| **F1 Score** | Balance between precision & recall | Strong |
| **AUC-ROC** | Class separability | Excellent |

âœ… The KNN model effectively captured the **non-linear decision boundary** of the U-shaped data and provided high accuracy and generalization.

## ğŸ§  Key Learnings
- KNN performs effectively for **non-linear datasets** like U-shape.  
- **Cross-validation** helps determine the most optimal K value.  
- **Decision boundary visualization** gives clear insight into model behavior.

## ğŸ’» Technologies Used
- Python  
- Pandas  
- NumPy  
- Matplotlib  
- Scikit-learn  
- mlxtend

## ğŸ“ˆ Example Output
Best K Value: 3  
Accuracy: 0.95  
Precision: 0.93  
Recall: 0.94  
F1 Score: 0.94  
AUC-ROC: 0.97  

## ğŸš€ How to Run the Project
1. Clone this repository  
   `git clone https://github.com/yourusername/KNN-UShape-Classification.git`  
2. Open the project in Google Colab or Jupyter Notebook.  
3. Run all the cells sequentially.  
4. Observe the accuracy metrics and the decision boundary visualization.

## ğŸ§‘â€ğŸ’» Author
**Shaik Shabana**  
ğŸ“ Data Science Intern | Python & Machine Learning Enthusiast  
ğŸ”— [GitHub Profile](https://github.com/shaik-shabana05/KNN-Project/blob/main/S_KNN_project.ipynb)


